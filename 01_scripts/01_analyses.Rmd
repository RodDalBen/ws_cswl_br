---
title: "Data analyses for: Speech segmentation and cross-situational word learning in parallel"
author: "Rodrigo Dal Ben"
date: "March 25, 2021"
output: html_document
---

Last update: August 1, 2022

***

Data analyses script containing descriptive and inferential statistics, as well as visualizations for:

**Reference:** Dal Ben R., Prequero I. T., Souza, D. H., & Hay, J. F. (under review). Speech segmentation and cross-situational word learning in parallel. *Under Review* [*PsyArXiv preprint*](https://psyarxiv.com/pf4nr/)

**OSF:** [project](https://osf.io/rs2bm/)

**GitHub:** [repository](https://github.com/RodDalBen/ws_cswl_br)

**Feedback & suggestions:** <dalbenwork@gmail.com>

***

The script has the following structure:

1. Load packages
2. Prepare the data
3. Demographics
4. Visualizations
5. Descriptive statistics
6. Inferential statistics

***

# User preferences

Decide if you want to save figures and tables or just inspect them in R. 

```{r switch output}
# set to TRUE to save 
save_output = F
```

# Load packages

To increase the chances of reproducibility, we load packages through the `groundhog`.

```{r load package}
# change to TRUE to use groundhog
use_groundhog <- FALSE 

# developer session info
# R version 4.1.2 (2021-11-01)
# Platform: aarch64-apple-darwin20 (64-bit)
# Running under: macOS Monterey 12.2.1

# list of packages w/ version
pkgs <- c("here", # v1.0.1
          "tidyverse", # v1.3.1
          "boot", # v1.3-28
          "gmodels", # v2.18.1
          "lme4", # v.1-28
          "sjPlot", # v2.8.10
          "patchwork", # v1.1.1
          "janitor", # v2.1.0
          "RColorBrewer", # v1.1-2
          "tidylog", # v1.0.2
          "ggdist" # v3.1.1
          )

if(use_groundhog == TRUE){
# groundhog
pkgs_date <- "2021-08-10"
library(groundhog) # version: 1.4.0
groundhog::groundhog.library(pkg = pkgs, date = pkgs_date)

# clean
rm(pkgs, pkgs_date, use_groundhog)

}else{
# if necessary install
installed_pkgs <- pkgs %in% rownames(installed.packages())
if(any(installed_pkgs == F)){install.packages(pkgs[!installed_pkgs])}
# load packages
invisible(lapply(pkgs, library, character.only = T))
# clean
rm(installed_pkgs, pkgs, use_groundhog)
}

# avoid scientific notation
options(scipen = 0)
```

# Prepare data

Here we load 3 datasets:
1. WS + CSWL: main dataset;
2. WS: reanalysis dataset for word segementation only;
3. CSWL: reanalysis dataset for cross-situational word learning only.

Datasets 2 and 3 are not manipulated until the "Visualization" section and data is analyzed only in the "Comparison: joint vs. single tasks" section. Dataset 3 (CSWL) is already filtered for inattentive responses and outliers. Dataset is not. We remove outliers using the same parameters used for dataset 1, we do so under: Statitics > Inferential > Comparison > Prepare data > Remove outliers (code chunk #25).

```{r load data}
# WS + CSWL, WS, CSWL
load(here("02_data", "data_ws_cswl_br.rda"))
load(here("02_data", "reanalysis_data_ws_br.rda"))
load(here("02_data", "reanalysis_data_cswl_br.rda"))

# rename experiment from ws only 
data_ws_br <- 
  data_ws_br %>% 
  mutate(experiment = "ws only")

# filter relevant data from cswl only & add columns to match the other dataset
data_cswl_br <- 
  data_cswl_br %>% 
  mutate(experiment = "cswl only", 
         speech_version = NA,
         block_ws = NA,
         target_audio_ws = NA,
         distractor_audio_ws = NA,
         distractor_audio_type_ws = NA,
         freq_pair = NA,
         sona_gift_card = NA)
  
# check number of participants on each experiment and speech version
data_ws_cswl_br %>% group_by(experiment, speech_version) %>% distinct(p_n_unique) %>% count()
data_ws_br %>% group_by(experiment, speech_version) %>% distinct(p_n_unique) %>% count()
data_cswl_br %>% group_by(experiment) %>% distinct(p_n_unique) %>% count()
```

## Remove inattentive/non-compliance

For the **go/no-go condition** (online data collection) we remove participants who: 

1. Had responses with reaction time greater than 3 SDs
2. Failed in more than 2 of the 5 catch trials during training
3. Failed in more than 2 of the 6 catch trials at word segmentation test
4. Reported using cellphone (against instructions)
5. Reported annotating during the task (against instructions). 

```{r inattentive/non-compliance}
# reaction time of catch trials
rt_inatt_experiment2 <- 
  data_ws_cswl_br %>% 
  filter(experiment == 2,
         trial_type %in% c("catch test ws", "catch training")
         ) %>% 
  group_by(trial_type) %>% 
  summarise(avg_rt = mean(rt, na.rm = T), 
            rt_3sd = 3*sd(rt, na.rm = T),
            cutoff_low = avg_rt - rt_3sd,
            cutoff_up = avg_rt + rt_3sd,
            )

# inattention by participant and trial type
inatt_experiment2 <- 
  data_ws_cswl_br %>% 
  filter(experiment == 2,
         trial_type %in% c("catch cellphone", "catch annotation", "catch test ws", "catch training") # 5
         ) %>% 
  group_by(p_n_unique, trial_type) %>% 
  mutate(    
    is_correct = case_when(trial_type == "catch cellphone" & key_pressed == "n" ~ 1,
                           trial_type == "catch cellphone" & key_pressed == "s" ~ 0,
                           trial_type == "catch annotation" & key_pressed == "n" ~ 1,
                           trial_type == "catch annotation" & key_pressed == "s" ~ 0,
                           T ~ as.double(is_correct)),
    include_rt = case_when(trial_type == "catch test ws" & 
                             rt < rt_inatt_experiment2$cutoff_up[1] & rt > rt_inatt_experiment2$cutoff_low[1] ~ T,
                           trial_type == "catch training" & 
                             rt < rt_inatt_experiment2$cutoff_up[2] & rt > rt_inatt_experiment2$cutoff_low[2] ~ T,
                           T ~ F)
    ) %>%
  summarise(sum_is_correct = sum(is_correct, na.rm = T),
            sum_rt = sum(include_rt, na.rm = T)
            ) %>%
  mutate(include_is_correct = case_when(trial_type == "catch test ws" & sum_is_correct >= 5 ~ T, # 5 out of 6 
                                        trial_type == "catch training" & sum_is_correct >= 4 ~ T, # 4 out of 5
                                        trial_type == "catch cellphone" & sum_is_correct == 1 ~ T, 
                                        trial_type == "catch annotation" & sum_is_correct == 1 ~ T,
                                        T ~ F),
         include_rt = case_when(trial_type == "catch test ws" & sum_rt != 6 ~ F, 
                                trial_type == "catch training" & sum_rt != 5 ~ F, 
                                T ~ T),
         include = if_else(include_is_correct == T & include_rt == T, T, F)
         )

# inattention by trial type
inatt_trial_type <- 
  inatt_experiment2 %>% 
  group_by(trial_type) %>% 
  summarise(include_is_correct = sum(include_is_correct),
            include_rt = sum(include_rt),
            include_final = sum(include))

# inattention by participant
inatt_participant <- 
  inatt_experiment2 %>% 
  group_by(p_n_unique) %>% 
  summarise(include_final = if_else(sum(include) == 4, T, F))
  
# final list of excluded participants
exclude_list <- 
  inatt_participant %>% 
  filter(include_final == F) # 10 participants excluded (35 remaining)
  
# exclude participants from dataset
data_filtered_v1 <- 
  data_ws_cswl_br %>% 
  filter(!p_n_unique %in% exclude_list$p_n_unique)

# double check n by experiment and speech version
data_filtered_v1 %>% group_by(experiment, speech_version) %>% distinct(p_n_unique) %>% count() # 35 on go/no-go
```

## Remove outliers

We remove test trials (both ws and cswl), for all conditions, with reaction time greater than 3 SDs. 

```{r rt outliers}
# calculate sd
rt_3sd <-
  data_filtered_v1 %>% 
  group_by(experiment, speech_version, trial_type) %>% 
  filter(trial_type == "test ws" | trial_type == "test cswl") %>% 
  summarise(rt_avg = mean(rt, na.rm = T),
            rt_3sd = 3*sd(rt, na.rm = T),
            cutoff_low = rt_avg - rt_3sd,
            cutoff_up = rt_avg + rt_3sd)

rt_3sd

# visualize 3 SDs, facet by experiment/speech_version
data_filtered_v1 %>% 
  filter(trial_type == "test ws" | trial_type == "test cswl") %>% 
  ggplot(aes(x = rt)) +
  geom_histogram() +
  facet_wrap(speech_version ~ trial_type)

# remove outliers
data_filtered_v2 <- 
  data_filtered_v1 %>% 
  mutate(include_trial = case_when(trial_type == "test ws" & speech_version == "L_balanced" & rt > rt_3sd$cutoff_up[2] ~ F,
                                   trial_type == "test cswl" & speech_version == "L_balanced" & rt > rt_3sd$cutoff_up[1] ~ F,
                                   
                                   trial_type == "test ws" & speech_version == "L_aligned" & rt > rt_3sd$cutoff_up[4] ~ F,
                                   trial_type == "test cswl" & speech_version == "L_aligned" & rt > rt_3sd$cutoff_up[3] ~ F,
                                   
                                   experiment == 1 & trial_type == "test ws" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[6] ~ F,
                                   experiment == 1 & trial_type == "test cswl" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[5] ~ F,
                                   
                                   experiment == 2 & trial_type == "test ws" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[8] ~ F,
                                   experiment == 2 & trial_type == "test cswl" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[7] ~ F,
                                   
                                   T ~ T
                                   ),
         distractor_audio_type_ws = factor(distractor_audio_type_ws, levels = c("word", "part_word", "non_word"))
         )

# summary of exclude trials by experiment/speech_version
data_filtered_v2 %>% 
  filter(trial_type == "test ws" | trial_type == "test cswl") %>% 
  group_by(experiment, include_trial, trial_type) %>% # , speech_version
  count() %>% 
  spread(include_trial, n) %>% 
  mutate(perc_excl = `FALSE`/`TRUE`)

# exclude trials
data_filtered_v2 <- 
  data_filtered_v2 %>% 
  filter(include_trial == T) %>% 
  select(-include_trial) # 70 trials (1% overall)
```

# Demographics

Sample size, gge (average, sd, range), and gender.

```{r demographics}
# demographics
data_filtered_v2 %>% 
  group_by(p_n_unique) %>% 
  slice_head() %>%
  ungroup() %>% 
  group_by(experiment) %>%  #, speech_version) %>% 
  mutate(tmp_gender = if_else(gender == "female", 1, 0)) %>%
  summarise(n = n(), 
            female = sum(tmp_gender), 
            age_avg = round(mean(age, na.rm = T), 2),
            age_sd = round(sd(age, na.rm = T), 2),
            age_max = max(age, na.rm = T),
            age_min = min(age, na.rm = T), 
            )
```

# Visualizations

* Mean performance on each task for each language;
* Correlation between performance and self-evaluation (keys 1 to 4 transformed to proportion .25 to 1);
* Correlation between performance on ws and cswl;

## Prepare data

Summary data, 1 data point per participant. 

```{r summary data plots}
# summary data for performance plot
data_summ_plot <- 
  data_filtered_v2 %>% 
  group_by(experiment, speech_version, p_n_unique, trial_type) %>%
  filter(trial_type %in% c("self evaluation cswl", "self evaluation ws", "test ws", "test cswl")) %>% 
  mutate(trial_type = factor(trial_type, levels = c("test ws", "test cswl", "self evaluation ws", "self evaluation cswl")),
         resp = case_when(trial_type == "self evaluation ws" | trial_type == "self evaluation cswl" ~ as.integer(key_pressed), 
                                    T ~ is_correct)) %>% 
  summarise(avg_resp = mean(resp, na.rm = T)) %>% 
  mutate(speech_version_label = case_when(speech_version == "L_balanced" ~ "Balanced", 
                                          speech_version == "L_aligned" ~ "Aligned", 
                                          speech_version == "L_conflict" ~ "Conflict"),
         speech_version_label = factor(speech_version_label, levels = c("Balanced", "Aligned", "Conflict"))) 
  
data_summ_plot

# summary data by stimuli type
## frequency visual (300 vs. 150) exp 1 and 2
data_summ_plot_freq <- 
  data_filtered_v2 %>% 
  filter(trial_type == "test cswl") %>% 
  group_by(experiment, speech_version, freq_pair, p_n_unique) %>%
  summarise(avg_resp = mean(is_correct, na.rm = T)) %>% 
  mutate(speech_version_label = case_when(speech_version == "L_balanced" ~ "Balanced", 
                                          speech_version == "L_aligned" ~ "Aligned", 
                                          speech_version == "L_conflict" ~ "Conflict"),
         speech_version_label = factor(speech_version_label, levels = c("Balanced", "Aligned", "Conflict")),
         freq_pair = factor(freq_pair, levels = c("low", "high"))) 
  
levels(data_summ_plot_freq$freq_pair)

data_summ_plot_freq

## auditory type experiment 2
data_summ_plot_audio_type <- 
  data_filtered_v2 %>% 
  filter(experiment == 2, trial_type == "test ws") %>% 
  group_by(experiment, speech_version, distractor_audio_type_ws, p_n_unique) %>%
  summarise(avg_resp = mean(is_correct, na.rm = T)) %>% 
  mutate(speech_version_label = case_when(speech_version == "L_conflict" ~ "Conflict"),
         speech_version_label = factor(speech_version_label)
         ) %>% 
  ungroup()
  
data_summ_plot_audio_type

### data for stacked positive and negative bar plot
data_summ_plot_audio_type_stacked <- 
  data_summ_plot_audio_type %>% 
  mutate(positive = avg_resp,
         negative = (1-avg_resp)*-1) %>% 
  select(distractor_audio_type_ws, positive, negative) %>%
  pivot_longer(!distractor_audio_type_ws, names_to = "direction", values_to = "avg_resp") %>%
  mutate(direction = factor(direction, levels = c("positive", "negative")))
  
data_summ_plot_audio_type_stacked

# summary data for correlation plot
# convert from 1, 2, 3, 4 to 0.25, 0.5, 0.75, 1 (respectively)
data_summ_correlation <- 
  data_summ_plot %>% 
  group_by(experiment, speech_version, p_n_unique) %>% 
  mutate(avg_resp = if_else(trial_type %in% c("self evaluation ws", "self evaluation cswl"), avg_resp*0.25, avg_resp)
         ) %>% 
  spread(trial_type, avg_resp)

data_summ_correlation

# reanalysis: ws only
data_summ_plot_ws_only <- 
  data_ws_br %>% 
  group_by(experiment, speech_version, p_n_unique, trial_type) %>%
  filter(trial_type == "test ws") %>% 
  mutate(experiment = "ws only") %>% 
  summarise(avg_resp = mean(is_correct, na.rm = T))

data_summ_plot_ws_only

# reanalysis: cswl only
data_summ_plot_cswl_only <- 
  data_cswl_br %>% 
  group_by(experiment, speech_version, p_n_unique, trial_type) %>%
  filter(trial_type == "test cswl") %>%
  mutate(experiment = "cswl only",
         speech_version = "cswl only") %>% 
  summarise(avg_resp = mean(is_correct, na.rm = T))

data_summ_plot_cswl_only

# joint dataset
data_summ_plot_all <- 
  data_summ_plot %>%
  filter(experiment == 1, # 2AFC only
         trial_type %in% c("test ws", "test cswl")) %>% 
  mutate(experiment = "ws + cswl joint") %>%
  rbind(., data_summ_plot_ws_only) %>% 
  rbind(., data_summ_plot_cswl_only) %>% 
  mutate(experiment = factor(experiment, levels = c("ws only", "cswl only", "ws + cswl joint")),
         speech_version_label = case_when(speech_version == "L_balanced" ~ "Balanced", 
                                          speech_version == "L_aligned" ~ "Aligned", 
                                          speech_version == "L_conflict" ~ "Conflict", 
                                          TRUE ~ "CSWL only"),
         speech_version_label = factor(speech_version_label, levels = c("CSWL only", "Balanced", "Aligned", "Conflict")))

levels(data_summ_plot_all$experiment)
levels(data_summ_plot_all$speech_version_label)
```

## Plots

### Experiment 1: Speech segmentation

* Performance
* Self-evaluation

```{r exp1 ws performance & corr plot}
plot_perf_seg_exp1 <- 
  data_summ_plot %>% 
  filter(experiment == 1,
         trial_type == "test ws") %>% 
  ggplot(aes(x = factor(1), y = avg_resp)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.4) + # bootstrap 95% CIs
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  geom_dotplot(binaxis = "y", 
               dotsize = 1, 
               alpha = 0.2, 
               stackdir = "down") +
  annotate("segment", x = -Inf, xend = Inf, y = 0.5, yend = 0.5, linetype = "dashed", alpha = 0.6) + # chance level ws
  facet_wrap(~ speech_version_label) +
  labs(title = "Speech segmentation", y = "Word selection") + 
  theme_classic(base_size = 10) + 
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

plot_perf_seg_exp1

# Exp 1 speech segmentation performance and self-evaluation
plot_corr_seg_eval_exp1 <- 
  data_summ_correlation %>%
  filter(experiment == 1) %>%
  mutate(label = case_when(speech_version_label == "Balanced" ~ "italic(r[s])~`=`~0.45",
                           speech_version_label == "Aligned" ~ "italic(r[s])~`=`~0.48",
                           speech_version_label == "Conflict" ~ "italic(r[s])~`=`~0.12"
                           )) %>% 
  ggplot(aes(y = `test ws`, x = `self evaluation ws`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, fullrange = T, size = 0.5) +
  facet_wrap(~ speech_version_label) +
  geom_text(mapping = aes(x = -Inf, y = -Inf, label = label),
            parse = T,
            hjust = -0.5, vjust = -1,
            size = 2.5,
            color = "darkgrey"
            ) +
  scale_size_area() +
  labs(title = "Speech segmentation and self-evaluation", 
       y = "Word selection", 
       x = "Self-evaluation") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5,
        panel.spacing = unit(0.8, "lines"))

plot_corr_seg_eval_exp1

# joint plot
plot_joint_seg_exp1 <- 
  plot_perf_seg_exp1 / plot_corr_seg_eval_exp1 + 
  plot_annotation(title = "Experiment 1", tag_levels = "A")

# save or not
if(save_output == T){
  ggsave(plot = plot_joint_seg_exp1, 
         filename = here("03_output_graphics", "plot_joint_seg_exp1.png"),
         width = 14, height = 14, units = "cm", dpi = 300)
}
```

#### Experiment 1: Joint vs. single task: Here we use data from other experiments with a single task.

```{r exp1 ws joint vs single task}
plot_ws_only <- 
  data_summ_plot_all %>% 
  filter(experiment %in% c("ws only", "ws + cswl joint"),
         trial_type == "test ws") %>% 
  ggplot(aes(x = experiment, y = avg_resp)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.2) + # bootstrap CIs
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  geom_dotplot(binaxis = "y", 
               dotsize = 0.5, 
               alpha = 0.2, 
               stackdir = "down") +
  scale_x_discrete(labels = c("WS\nonly", "WS &\nCSWL")) +
  facet_wrap(~ speech_version_label) +
  annotate("segment", x = -Inf, xend = Inf, y = 0.5, yend = 0.5, linetype = "dashed", alpha = 0.6) + # chance level ws
  labs(title = "Experiment 1\nSegmentation only vs. simultaneous task", y = "Word selection", x = "Experiment") + 
  theme_classic(base_size = 10)

plot_ws_only

# save or not
if(save_output == T){
  ggsave(plot = plot_ws_only, 
         filename = here("03_output_graphics", "plot_ws_only_comparison.png"),
         width = 12, height = 8, units = "cm", dpi = 300)
}
```

### Experiment 1: Cross-situational word learning

* Performance
* Self-evaluation

```{r exp1 cswl performance & corr plot}
# experiment 1: mapping by pair frequency
plot_perf_map_freq_exp1 <- 
  data_summ_plot_freq %>% 
  filter(experiment == 1) %>% 
  ggplot(aes(x = freq_pair, y = avg_resp)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.4) + # bootstrap CIs
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  #geom_count(alpha = 0.2) + # uncomment for count data
  #geom_dotplot(binaxis = "y", # uncomment for raw data 
  #             dotsize = 0.5, 
  #             alpha = 0.2, 
  #             stackdir = "down") +
  annotate("segment", x = -Inf, xend = Inf, y = 0.25, yend = 0.25, linetype = "dashed", alpha = 0.6) + # chance level cswl
  facet_wrap(~ speech_version_label) +
  scale_x_discrete(labels = c("Low", "High")) +
  labs(title = "Mapping by frequency", 
       y = "Object selection",
       x = "Pair frequency") + 
  theme_classic(base_size = 10)

plot_perf_map_freq_exp1

# experiment 1: mapping and self evaluation
plot_corr_map_eval_exp1 <- 
  data_summ_correlation %>%
  filter(experiment == 1) %>%
  mutate(label = case_when(speech_version_label == "Balanced" ~ "italic(r[s])~`=`~0.9",
                         speech_version_label == "Aligned" ~ "italic(r[s])~`=`~0.59",
                         speech_version_label == "Conflict" ~ "italic(r[s])~`=`~0.52")) %>% 
  ggplot(aes(y = `test cswl`, x = `self evaluation cswl`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, size = 0.5, fullrange = T) +
  facet_wrap(~ speech_version_label) +
  geom_text(mapping = aes(x = -Inf, y = -Inf, label = label),
          parse = T,
          hjust = -2, vjust = -1,
          size = 2.5,
          color = "darkgrey") +
  scale_size_area() +
  labs(title = "Mapping and self-evaluation", 
       y = "Object selection", 
       x = "Self-evaluation") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5,
        panel.spacing = unit(0.8, "lines"))

plot_corr_map_eval_exp1

# joint plot
plot_joint_map_exp1 <- 
  plot_perf_map_freq_exp1 / plot_corr_map_eval_exp1 + 
  plot_annotation(title = "Experiment 1", tag_levels = "A")

# save or not
if(save_output == T){
  ggsave(plot = plot_joint_map_exp1, 
         filename = here("03_output_graphics", "plot_joint_map_exp1.png"),
         width = 14, height = 14, units = "cm", dpi = 300)
}
```

#### Experiment 1: Joint vs. single task

```{r exp1 cswl joint vs single task}
plot_cswl_only <- 
  data_summ_plot_all %>% 
  filter(experiment %in% c("cswl only", "ws + cswl joint"),
         trial_type == "test cswl") %>%
  ggplot(aes(x = factor(1), y = avg_resp)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.2) + # boot CIs
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  geom_dotplot(binaxis = "y", 
               dotsize = 0.5, 
               alpha = 0.2, 
               stackdir = "down") +
  annotate("segment", x = -Inf, xend = Inf, 
           y = 0.25, yend = 0.25, 
           linetype = "dashed", alpha = 0.6) + # chance level cswl
  facet_grid(. ~ speech_version_label) +
  labs(title = "Experiment 1\nMapping only vs. parallel experiment", y = "Object selection") + 
  theme_classic(base_size = 10) +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

plot_cswl_only

# save or not
if(save_output == T){
  ggsave(plot = plot_cswl_only, 
         filename = here("03_output_graphics", "plot_cswl_only_comparison.png"),
         width = 12, height = 8, units = "cm", dpi = 300)
}
```

### Experiment 1: Correlation speech segmentation and cross-situational word learning

```{r exp1 correlation plot seg map}
# overall stats
plot_corr_seg_map_exp1 <- 
  data_summ_correlation %>%
  filter(experiment == 1) %>% 
  mutate(label = case_when(speech_version_label == "Balanced" ~ "italic(r[s])~`=`~0.49", # calculate on line 1115
                         speech_version_label == "Aligned" ~ "italic(r[s])~`=`~0.52",
                         speech_version_label == "Conflict" ~ "italic(r[s])~`=`~0.42")) %>% 
  ggplot(aes(y = `test ws`, x = `test cswl`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, size = 0.5, fullrange = T) +
  facet_wrap(~ speech_version_label) +
  geom_text(mapping = aes(x = -Inf, y = -Inf, label = label),
          parse = T,
          hjust = -0.2, vjust = -1,
          size = 2.5,
          color = "darkgrey") +
  coord_cartesian(ylim = c(0, 1), xlim = c(0,1)) +
  scale_size_area() +
  labs(title = "By Language",
       y = "Word selection", x = "Object selection") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5,
        panel.spacing = unit(0.8, "lines"))

plot_corr_seg_map_exp1

# median split for Conflict Language
plot_corr_seg_map_conflict_median_split_exp1 <- 
  data_summ_correlation %>%
  filter(experiment == 1,
         speech_version_label == "Conflict") %>% 
  ungroup() %>% 
  mutate(median_split_ws = case_when(`test ws` > median(`test ws`) ~ "Above Median",
                                     TRUE ~ "Below Median"), 
    label = case_when(median_split_ws == "Above Median" ~ "italic(r[s])~`=`~0.45", # calculate on line 1129
                      median_split_ws == "Below Median" ~ "italic(r[s])~`=`~0.003")) %>% 
  ggplot(aes(y = `test ws`, x = `test cswl`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, size = 0.5, fullrange = T) +
  facet_wrap(~ median_split_ws) +
  geom_text(mapping = aes(x = -Inf, y = -Inf, label = label),
          parse = T,
          hjust = -0.2, vjust = -1,
          size = 2.5,
          color = "darkgrey") +
  coord_cartesian(ylim = c(0, 1), xlim = c(0,1)) +
  scale_size_area() +
  labs(title = "Conflict Language by Median Split",
       y = "Word selection", x = "Object selection") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5,
        panel.spacing = unit(0.8, "lines"))

plot_corr_seg_map_conflict_median_split_exp1

# joint plot
plot_joint_corr_seg_map_exp1 <- 
  plot_corr_seg_map_exp1 / plot_corr_seg_map_conflict_median_split_exp1 + 
  plot_annotation(title = "Experiment 1\nCorrelation between segmentation and mapping", tag_levels = "A")

# save or not
if(save_output == T){
  ggsave(plot = plot_joint_corr_seg_map_exp1, 
         filename = here("03_output_graphics", "plot_joint_corr_seg_map_exp1.png"),
         width = 14, height = 14, units = "cm", dpi = 300)
}
```

### Experiment 2: Speech Segmentation

* Performance
* Self-evaluation

```{r exp 2 speech segmentation performance and self-evaluation}
# Speech segmentation performance
plot_perf_seg_exp2 <- 
  data_summ_plot %>% 
  filter(experiment == 2,
         trial_type == "test ws") %>% 
  ggplot(aes(x = factor(1), y = avg_resp)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.4) + # bootstrap 95% CIs
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  geom_dotplot(binaxis = "y", 
               dotsize = 1.5, 
               alpha = 0.2, 
               stackdir = "down") +
  annotate("segment", x = -Inf, xend = Inf, y = 0.5, yend = 0.5, linetype = "dashed", alpha = 0.6) + # chance level ws
  coord_cartesian(ylim = c(0, 1)) +
  scale_size_area() +
  labs(title = "Speech segmentation", y = "Word selection") + 
  theme_classic(base_size = 10) + 
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

plot_perf_seg_exp2

# Exp 2 self-evaluation
plot_corr_seg_eval_exp2 <- 
  data_summ_correlation %>%
  filter(experiment == 2) %>%
  ggplot(aes(y = `test ws`, x = `self evaluation ws`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, fullrange = T, size = 0.5) +
  coord_cartesian(ylim = c(0, 1), xlim = c(0,1)) +
  annotate("text", x = -Inf, y = -Inf, 
           label = "italic(r[s])~`=`~0.08",
           parse = TRUE,
           hjust = -0.5, vjust = -1,
           size = 2.5,
           color = "darkgrey"
           ) +
  scale_size_area() +
  labs(title = "Speech segmentation \nand self-evaluation", 
       y = "Word selection", 
       x = "Self-evaluation") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5,
        panel.spacing = unit(0.8, "lines"),
        axis.title.y = element_blank(),
        axis.text.y = element_blank())

plot_corr_seg_eval_exp2

# stacked bar plot by stimuli type 
plot_perf_sti_type_seg_exp2 <- 
  data_summ_plot_audio_type_stacked %>% 
  ggplot(aes(x = distractor_audio_type_ws, y = avg_resp, fill = direction)) +
  stat_summary(fun.y = "mean", geom = "bar") +
  ylim(c(-1, 1)) +
  scale_fill_manual(values = c("darkgrey", "grey")) +
  scale_x_discrete(labels = c("Word","Part-word","Non-word")) +
  labs(x = "Stimuli type", 
       y = "Accuracy", 
       title = "Evaluation by stimuli type") +
  theme_classic(base_size = 10) +
  theme(legend.position = "none")

plot_perf_sti_type_seg_exp2

# joint plot
plot_joint_seg_exp2 <- 
  (plot_perf_seg_exp2 + plot_corr_seg_eval_exp2) / plot_perf_sti_type_seg_exp2 + 
  plot_annotation(title = "Experiment 2", tag_levels = "A")

# save or not
if(save_output == T){
  ggsave(plot = plot_joint_seg_exp2, 
         filename = here("03_output_graphics", "plot_joint_seg_exp2.png"),
         width = 14, height = 14, units = "cm", dpi = 300)
}
```

### Experiment 2: Cross-situational word learning

* Performance by pair frequency (300 or 150)
* Self-evaluation

```{r exp2 performance & corr map}
plot_map_freq_exp2 <- 
  data_summ_plot_freq %>% 
  filter(experiment == 2) %>% 
  ggplot(aes(x = freq_pair, y = avg_resp)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.4) + # bootstrap CIs
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  #geom_count(alpha = 0.2) + # uncomment for count data
  #geom_dotplot(binaxis = "y", # uncomment for raw data 
  #             dotsize = 0.5, 
  #             alpha = 0.2, 
  #             stackdir = "down") +
  scale_x_discrete(labels = c("Low", "High")) +
  annotate("segment", x = -Inf, xend = Inf, y = 0.25, yend = 0.25, linetype = "dashed", alpha = 0.6) + # chance level cswl
  labs(title = "Mapping by \npair frequency", 
       y = "Object selection", 
       x = "Pair frequency") + 
  theme_classic(base_size = 10)

plot_map_freq_exp2

# experiment 2: mapping and self evaluation
plot_corr_map_eval_exp2 <- 
  data_summ_correlation %>%
  filter(experiment == 2) %>%
  ggplot(aes(y = `test cswl`, x = `self evaluation cswl`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, size = 0.5, fullrange = T) +
  scale_size_area() +
  annotate("text", x = -Inf, y = -Inf, 
           label = "italic(r[s])~`=`~0.67",
           parse = TRUE,
           hjust = -3.5, vjust = -1,
           size = 2.5,
           color = "darkgrey"
           ) +
  labs(title = "Mapping \nand self-evaluation", 
       y = "Object selection", 
       x = "Self-evaluation") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5,
        panel.spacing = unit(0.8, "lines"),
        axis.title.y = element_blank(),
        axis.text.y = element_blank())

plot_corr_map_eval_exp2

# joint plot
plot_joint_map_exp2 <- 
  plot_map_freq_exp2 + plot_corr_map_eval_exp2 + 
  plot_annotation(title = "Experiment 2", tag_levels = "A")

# save or not
if(save_output == T){
  ggsave(plot = plot_joint_map_exp2, 
         filename = here("03_output_graphics", "plot_joint_map_exp2.png"),
         width = 14, height = 8, units = "cm", dpi = 300)
}
```

### Experiment 2: Correlation speech segmentation and cross-situational word learning

```{r exp2 correlation plot seg map}
# overall
plot_corr_seg_map_exp2 <- 
  data_summ_correlation %>%
  filter(experiment == 2) %>% 
  ggplot(aes(y = `test ws`, x = `test cswl`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, fullrange = T, size = 0.5) +
  coord_cartesian(ylim = c(0, 1), xlim = c(0, 1)) +
  scale_size_area() +
  annotate("text", x = -Inf, y = -Inf, 
           label = "italic(r[s])~`=`~0.32",
           parse = TRUE,
           hjust = -1, vjust = -1,
           size = 2.5,
           color = "darkgrey"
           ) +
  labs(y = "Word selection", x = "Object selection") + 
  theme_classic(base_size = 10) +
  theme(legend.position = "none")

plot_corr_seg_map_exp2

# median split 
plot_corr_seg_map_median_split_exp2 <- 
  data_summ_correlation %>%
  filter(experiment == 2) %>% 
  ungroup() %>% 
  mutate(median_split_ws = case_when(`test ws` > median(`test ws`) ~ "Above Median",
                                     TRUE ~ "Below Median"), 
         label = case_when(median_split_ws == "Above Median" ~ "italic(r[s])~`=`~0.05", # calculate on line 1129
                           median_split_ws == "Below Median" ~ "italic(r[s])~`=`~0.11")) %>% 
  ggplot(aes(y = `test ws`, x = `test cswl`)) +
  geom_count(alpha = 0.2) +
  geom_smooth(method = "lm", se = F, color = "black", alpha = 0.7, size = 0.5, fullrange = T) +
  facet_wrap(~ median_split_ws) +
  geom_text(mapping = aes(x = -Inf, y = -Inf, label = label),
          parse = T,
          hjust = -0.2, vjust = -1,
          size = 2.5,
          color = "darkgrey") +
  coord_cartesian(ylim = c(0, 1), xlim = c(0,1)) +
  scale_size_area() +
  labs(title = "By Median Split",
       y = "Word selection", x = "Object selection") + 
  theme_classic(base_size = 10) +
  theme(legend.position = "none",
        panel.spacing = unit(0.8, "lines"))

plot_corr_seg_map_median_split_exp2

# joint plot
plot_joint_corr_seg_map_exp2 <- 
  plot_corr_seg_map_exp2 / plot_corr_seg_map_median_split_exp2 + 
  plot_annotation(title = "Experiment 2\nCorrelation between segmentation and mapping", tag_levels = "A")

# save or not
if(save_output == T){
  ggsave(plot = plot_joint_corr_seg_map_exp2, 
         filename = here("03_output_graphics", "plot_joint_corr_seg_map_exp2.png"),
         width = 14, height = 14, units = "cm", dpi = 300)
}
```

# Statistics

## Descriptive

Mean correct & sd

```{r descriptive}
# descriptive - take it all with a grain of salt, the real stats is done with mixed models below
data_summ_plot %>% 
  group_by(experiment, speech_version, trial_type) %>%
  summarise(avg = mean(avg_resp, na.rm = T), 
            sd = sd(avg_resp, na.rm = T),
            ci_low = gmodels::ci(avg_resp)[2],
            ci_high = gmodels::ci(avg_resp)[3],
            d = (avg - 0.5)/sd
            ) %>% 
  mutate(ci_low = if_else(trial_type %in% c("test ws", "test cswl"), ci_low, NA_real_),
         ci_high = if_else(trial_type %in% c("test ws", "test cswl"), ci_high, NA_real_),
         d = if_else(trial_type %in% c("test ws", "test cswl"), d, NA_real_),
         avg = if_else(trial_type %in% c("self evaluation ws", "self evaluation cswl"), avg*0.25, avg),
         sd = if_else(trial_type %in% c("self evaluation ws", "self evaluation cswl"), sd*0.25, sd)
         ) 

# descriptive by stimuli type
# Experiment 2 - segmentation 
data_summ_plot_audio_type %>% 
  group_by(distractor_audio_type_ws) %>% 
  summarise(avg = mean(avg_resp, na.rm = T),
            sd = sd(avg_resp, na.rm = T))

# Experiment 1 & 2 - mapping (high, low)
data_summ_plot_freq %>% 
  group_by(experiment, speech_version, freq_pair) %>% 
  summarise(avg = mean(avg_resp, na.rm = T),
            sd = sd(avg_resp, na.rm = T))

# Experiment 1 & 2 - mapping overall
data_summ_plot_freq %>% 
  group_by(experiment, speech_version) %>% 
  summarise(avg = mean(avg_resp, na.rm = T),
            sd = sd(avg_resp, na.rm = T))

# Previous studies
## Speech segmentation only
data_summ_plot_ws_only %>% 
  group_by(speech_version) %>% 
  summarise(avg = mean(avg_resp, na.rm = T),
            sd = sd(avg_resp, na.rm = T))
  
## Cross-situational word learning only
data_summ_plot_cswl_only %>% 
  ungroup() %>% 
  summarise(avg = mean(avg_resp, na.rm = T),
            sd = sd(avg_resp, na.rm = T))

```

## Inferential

We run 3 analyses:

1. Frequentist Logistic mixed model (`ws`, `cswl`);
  1.1. `WS`;
  1.2. `CSWL`;
2. Correlations:
  2.1. Between `ws` and `cswl` performance; 
  2.2. Between `self evaluation` and `ws` or `cswl` performance;

Given our binary outcome, odds ratio (OR) for each predictor serve as **effect sizes** estimations.

- Experiment 1: Balanced (intercept) -> Aligned -> Conflict -> Conflict
- Experiment 2: Against chance;
- Maximal random effects structure: `(participants|experiment)` does not have enough variability in the groups (3 words by 60 or 29 participants). 
- Pruned random effects structure: `(1|item) + (1|participant)`, intercepts for both stimuli and participants.

#### Word-segmentation

**Experiment 1**

```{r freq ws experiment 1}
# experiment 1
mod_freq_ws_experiment1 <-
  data_filtered_v2 %>% 
  filter(experiment == 1,
         trial_type == "test ws") %>% 
  glmer(is_correct ~ logit(chance_level) + speech_version + (1|target_audio_ws) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_ws_experiment1)
sjPlot::tab_model(mod_freq_ws_experiment1,
                  show.p = F,
                  title = "Frequentist, Experiment 1 - Segmentation")

# save or not
if(save_output == T){
sjPlot::tab_model(mod_freq_ws_experiment1,
                  show.p = F,
                  title = "Frequentist, Experiment 1 - Segmentation", 
                  file = here("03_output_graphics", "mod_freq_ws_exp1.doc"))
}
```

**Experiment 2**

On the go/no-go trials, participants heard either *non-words*, *words*, or *part-words*. Here we model the OR for each of this stimuli status.

```{r freq ws experiment 2}
# experiment 2
mod_freq_ws_experiment2 <-
  data_filtered_v2 %>% 
  filter(experiment == 2,
         trial_type == "test ws") %>% 
  glmer(is_correct ~ logit(chance_level) + distractor_audio_type_ws + (1|target_audio_ws) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_ws_experiment2)
sjPlot::tab_model(mod_freq_ws_experiment2,
                  show.p = F,
                  title = "Frequentist, Experiment 2 - Segmentation")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_freq_ws_experiment2,
                  show.p = F,
                  title = "Frequentist, Experiment 2 - Segmentation", 
                  file = here("03_output_graphics", "mod_freq_ws_exp2.doc"))
}
```

#### Cross-situational word learning

**experiment 1**

```{r freq cswl experiment 1}
# maximal random effects
mod_freq_cswl_experiment1 <-
  data_filtered_v2 %>% 
  filter(experiment == 1,
         trial_type == "test cswl") %>%
  mutate(freq_pair = factor(freq_pair, levels = c("low", "high"))) %>% 
  glmer(is_correct ~ logit(chance_level) + speech_version*freq_pair + (1|target_visual) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_cswl_experiment1)
sjPlot::tab_model(mod_freq_cswl_experiment1,
                  show.p = F,
                  title = "Frequentist, Experiment 1 - Mapping")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_freq_cswl_experiment1,
                  show.p = F,
                  title = "Frequentist, Experiment 1 - Mapping", 
                  file = here("03_output_graphics", "mod_freq_map_exp1.doc"))
}

# inspection plots
data_filtered_v2 %>% 
  filter(experiment == 1,
         trial_type == "test cswl") %>% 
  ggplot(aes(x = is_correct)) +
  geom_histogram() +
  facet_wrap(speech_version ~ freq_pair) +
  theme_light()
```

**experiment 2**

```{r freq cswl experiment 2}
# maximal random effects
mod_freq_cswl_experiment2 <-
  data_filtered_v2 %>% 
  filter(experiment == 2,
         trial_type == "test cswl") %>% 
  glmer(is_correct ~ logit(chance_level) + freq_pair + (1|target_visual) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_cswl_experiment2)
sjPlot::tab_model(mod_freq_cswl_experiment2,
                  show.p = F,
                  title = "Frequentist, Experiment 2 - Mapping")

# save or not
if(save_output == T){
sjPlot::tab_model(mod_freq_cswl_experiment2,
                  show.p = F,
                  title = "Frequentist, Experiment 2 - Mapping", 
                  file = here("03_output_graphics", "mod_freq_map_exp2.doc"))
}

# plots to confirm the distribution of responses
## histogram
data_filtered_v2 %>% 
  filter(experiment == 2,
         trial_type == "test cswl") %>% 
  ggplot(aes(x = is_correct)) +
  geom_histogram() +
  facet_wrap(speech_version ~ freq_pair) +
  theme_light()

# mean boostrap w/ violin
data_filtered_v2 %>% 
  filter(experiment == 2,
         trial_type == "test cswl") %>% 
  ggplot(aes(x = speech_version, y = is_correct, fill = freq_pair)) +
  geom_violin(position = position_dodge(0.85), alpha = 0.6, size = 0.3) +
  geom_point(position = position_jitterdodge(jitter.width = 0.15, dodge.width = 0.85), alpha = 0.3) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = 0.85)) + # boot CIs
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  scale_x_discrete(labels = "Conflict") +
  annotate("segment", x = 0, xend = 2, y = 0.25, yend = 0.25, linetype = "dashed") + # chance level cswl
  labs(title = "Experiment 2 - Mapping by pair frequency", 
       y = "Proportion of correct selection", 
       x = "Speech version") + 
  theme_classic(base_size = 10) +
  theme(legend.title.align = 0.5)
```

### Correlation

**WS and CSWL performance correlation**

```{r correlation ws cswl performance}
# overall corr across both experiments
data_summ_correlation %>% 
  group_by(experiment, speech_version) %>% 
  summarise(cor(`test ws`, `test cswl`, method = "spearman"))

# Conflict Language - Median split
## calculate median and range
data_summ_correlation %>% 
  filter(speech_version == "L_conflict") %>% 
  group_by(experiment) %>% 
  summarise(median_ws = median(`test ws`),
            iqr = IQR(`test ws`))
  
## Spearman by median split
data_summ_correlation %>% 
  filter(speech_version == "L_conflict") %>% 
  group_by(experiment) %>% 
  mutate(median_split = case_when(`test ws` > median(`test ws`) ~ "above",
                               TRUE ~ "below")
         ) %>% 
  group_by(experiment, median_split) %>% 
  summarise(cor(`test ws`, `test cswl`, method = "spearman"))
```

**WS and CSWL self evaluation correlation**

```{r correlation ws cswl self evaluation}
data_summ_correlation %>% 
  group_by(experiment, speech_version) %>% 
  summarise(cor_ws_self = cor(`test ws`, `self evaluation ws`, method = "spearman"),
            cor_cswl_self = cor(`test cswl`, `self evaluation cswl`, method = "spearman"))
```

### Comparison: parallel (joint) vs. single tasks

##### Prepare data

###### Remove outliers: dataset 2

We remove test trials (both ws and cswl), for all conditions, with reaction time greater than 3 SDs. 

```{r dataset 2 outliers}
# calculate sd
ds2_rt_3sd <-
  data_ws_br %>% 
  group_by(speech_version) %>% 
  filter(trial_type == "test ws") %>% 
  summarise(rt_avg = mean(rt, na.rm = T),
            rt_3sd = 3*sd(rt, na.rm = T),
            cutoff_low = rt_avg - rt_3sd,
            cutoff_up = rt_avg + rt_3sd)

ds2_rt_3sd

# visualize 3 SDs, facet by speech_version
data_ws_br %>% 
  filter(trial_type == "test ws") %>% 
  ggplot(aes(x = rt)) +
  geom_histogram() +
  facet_wrap(~ speech_version)

# remove outliers
data_ws_br_v2 <- 
  data_ws_br %>% 
  mutate(include_trial = case_when(trial_type == "test ws" & speech_version == "L_balanced" & rt > ds2_rt_3sd$cutoff_up[1] ~ F,
                                   trial_type == "test ws" & speech_version == "L_aligned" & rt > ds2_rt_3sd$cutoff_up[2] ~ F,
                                   trial_type == "test ws" & speech_version == "L_conflict" & rt > ds2_rt_3sd$cutoff_up[3] ~ F,
                                   T ~ T
                                   ))

# summary of exclude trials by experiment/speech_version
data_ws_br_v2 %>% 
  filter(trial_type == "test ws") %>% 
  group_by(include_trial) %>% # , speech_version) %>% 
  count() %>% 
  spread(include_trial, n) %>% 
  mutate(perc_excl = `FALSE`/`TRUE`)

# exclude trials
data_ws_br_v2 <- 
  data_ws_br_v2 %>% 
  filter(include_trial == T) %>% 
  select(-include_trial) # 24 trials (2% overall)
```

###### Combine datasets: 1 (ws + cswl), 2 (ws only), 3 (cswl only)

```{r prepare data comparison parallel vs single experiment}
# set common columns between datasets
col_diff <- intersect(names(data_filtered_v2), names(data_cswl_br))
col_diff_v2 <- intersect(col_diff, names(data_ws_br_v2))

# create dataset
data_filtered_v3 <- 
  data_filtered_v2 %>%
  select(col_diff_v2) %>% #keep only columns that intersect
  filter(experiment == 1) %>% # 2AFC
  mutate(experiment = "ws + cswl joint") %>% 
  filter(trial_type %in% c("test ws", "test cswl")) 

data_ws_br_v3 <- 
  data_ws_br %>% 
  select(col_diff_v2)

data_cswl_br_v2 <- 
  data_cswl_br %>% 
  select(col_diff_v2)

# join dataset
data_single_parallel <- 
  data_filtered_v3 %>% 
  rbind(., data_ws_br_v3) %>% 
  rbind(., data_cswl_br_v2) %>% 
  mutate(experiment = factor(experiment, levels = c("ws only", "cswl only", "ws + cswl joint")),
         speech_version = case_when(speech_version == "L_balanced" ~ "Balanced", 
                                    speech_version == "L_aligned" ~ "Aligned", 
                                    speech_version == "L_conflict" ~ "Conflict", 
                                    TRUE ~ "cswl only"),
         speech_version = factor(speech_version, levels = c("cswl only", "Balanced", "Aligned", "Conflict")))

# check factor levels
levels(data_single_parallel$experiment)
levels(data_single_parallel$speech_version)

# check number of participants on each experiment and speech version
data_single_parallel %>% group_by(experiment, speech_version) %>% distinct(p_n_unique) %>% count() # ok
```

##### Model

* Word-segmentation by experiment and speech version. We have data for each language on both the single and the joint task.

```{r ws model parallel vs single experiments}
# Balanced 
mod_joint_ws_balanced <- 
  data_single_parallel %>% 
  filter(speech_version == "Balanced",
         trial_type == "test ws") %>%
  lme4::glmer(is_correct ~ experiment + (1|p_n_unique),
              data = .,
              family = "binomial")

summary(mod_joint_ws_balanced)
sjPlot::tab_model(mod_joint_ws_balanced,
                  show.p = F,
                  title = "Speech segmentation - Balanced: single vs. parallel task")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_joint_ws_balanced,
                  show.p = F,
                  title = "Speech segmentation - Balanced: single vs. parallel task", 
                  file = here("03_output_graphics", "mod_freq_ws_balanced_joint.doc"))
}

# Aligned
mod_joint_ws_aligned <- 
  data_single_parallel %>% 
  filter(speech_version == "Aligned",
         trial_type == "test ws") %>%
  lme4::glmer(is_correct ~ experiment + (1|p_n_unique),
              data = .,
              family = "binomial")

summary(mod_joint_ws_aligned)
sjPlot::tab_model(mod_joint_ws_aligned,
                  show.p = F,
                  title = "Speech segmentation - Aligned: single vs. parallel task")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_joint_ws_aligned,
                  show.p = F,
                  title = "Speech segmentation - Aligned: single vs. parallel task", 
                  file = here("03_output_graphics", "mod_freq_ws_aligned_joint.doc"))
}

# Conflict - CONVERGENCE WARNING
mod_joint_ws_conflict <- 
  data_single_parallel %>% 
  filter(experiment %in% c("ws only", "ws + cswl joint"), 
         speech_version == "Conflict",
         trial_type == "test ws") %>%
  lme4::glmer(is_correct ~ experiment + (1|p_n_unique), # convergence warning, but results don't change: keeping both random slope (experiment) and intercept (participant), instead of only participant
              data = .,
              family = "binomial")

summary(mod_joint_ws_conflict)
sjPlot::tab_model(mod_joint_ws_conflict,
                  show.p = F,
                  title = "Speech segmentation - Conflict: single vs. parallel task")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_joint_ws_conflict,
                  show.p = F,
                  title = "Speech segmentation - Conflict: single vs. parallel task", 
                  file = here("03_output_graphics", "mod_freq_ws_conflict_joint.doc"))
}

# combined table
sjPlot::tab_model(mod_joint_ws_balanced, mod_joint_ws_aligned, mod_joint_ws_conflict,
                  show.p = F,
                  title = "Speech segmentation - single vs. parallel task: \n Balanced, Aligned, Conflict; 
                  [selection ~ experiment + (1|p_n_unique)]")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_joint_ws_balanced, mod_joint_ws_aligned, mod_joint_ws_conflict,
                  show.p = F,
                  title = "Speech segmentation - single vs. parallel task: \n Balanced, Aligned, Conflict; 
                  [selection ~ experiment + (1|p_n_unique)]", 
                  file = here("03_output_graphics", "mod_freq_ws_joint_tab.doc"))
}
```

* Cross-situational word learning by experiment and speech version. We have data for each language on the joint task. These will be compared to a baseline of cswl only.

```{r cswl model parallel vs single experiments}
# CSWL
# experiment + speech are combined in a single variable
mod_joint_cswl <- 
  data_single_parallel %>% 
  filter(experiment %in% c("cswl only", "ws + cswl joint"), 
         trial_type == "test cswl") %>%
  lme4::glmer(is_correct ~ speech_version + (1|p_n_unique), 
              data = .,
              family = "binomial")

summary(mod_joint_cswl)
sjPlot::tab_model(mod_joint_cswl,
                  show.p = F,
                  title = "Cross-situational word learning: single (intercept) vs. parallel task (Balanced, Aligned, Conflict; [selection ~ experiment:speech version + (1|p_n_unique)]")

# save or not
if(save_output == T){
  sjPlot::tab_model(mod_joint_cswl,
                  show.p = F,
                  title = "Cross-situational word learning: single (intercept) vs. parallel task (Balanced, Aligned, Conflict; [selection ~ experiment:speech version + (1|p_n_unique)]", 
                  file = here("03_output_graphics", "mod_freq_cswl_joint.doc"))
}

```

# Additional analysis: Potential effects of number of trials

In Experiment 1, we tested each word (3) against each part-word (3) twice, for a total of 18 2-forced-choice trials. 
In Experiment 2, we tested each word (3), part-word (3), and non-word (3), 6x, for a total of 53 go/no-go trials.

Here we explore whether this ammount of exposure to part-words and non-words influence participants' performance on speech segmentation tests.

```{r}
# Experiment 1 
mod_freq_ws_trials_exp1 <-
  data_filtered_v2 %>% 
  filter(experiment == 1,
         trial_type == "test ws") %>% 
  mutate(trial_number_mod = trial_number - 5) %>% # starting at 0
  glmer(is_correct ~ logit(chance_level) + speech_version * trial_number + (1|target_audio_ws) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_ws_trials_exp1)
sjPlot::tab_model(mod_freq_ws_trials_exp1,
                  show.p = F,
                  title = "Frequentist, Experiment 1 - Segmentation")

# Experiment 2
mod_freq_ws_trials_exp2 <-
  data_filtered_v2 %>% 
  filter(experiment == 2,
         trial_type == "test ws") %>% 
  mutate(trial_number_mod = trial_number - 5) %>% # starting at 0
  glmer(is_correct ~ logit(chance_level) + trial_number + (1|target_audio_ws) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_ws_trials_exp2)
sjPlot::tab_model(mod_freq_ws_trials_exp2,
                  show.p = F,
                  title = "Frequentist, Experiment 1 - Segmentation")
```

The analyses show that accuracy did not increased or descreased with trial number for both experiments. Visualization below. 

```{r}
# visualization
## Experiment 1
segmentation_acc_trial_exp1 <- 
data_filtered_v2 %>% 
  filter(experiment == 1,
         trial_type == "test ws") %>% 
  group_by(speech_version, trial_number) %>% 
  summarise(acc = mean(is_correct)) %>% 
  ggplot(aes(x = trial_number-4, y = acc)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~speech_version) +
  labs(
    title = "Experiment 1 - Speech segmentation, trial analysis",
    x = "Trial number", 
    y = "Accuracy") +
  theme_bw()

## Experiment 2
segmentation_acc_trial_exp2 <- 
data_filtered_v2 %>% 
  filter(experiment == 2,
         trial_type == "test ws") %>% 
  group_by(trial_number) %>% 
  summarise(acc = mean(is_correct)) %>% 
  ggplot(aes(x = trial_number - 10, y = acc)) +
  geom_point() +
  geom_smooth() +
  labs(
    title = "Experiment 2 - Speech segmentation, trial analysis",
    x = "Trial number", 
    y = "Accuracy") +
  theme_bw()

# joint visualization
plot_joint_segmentation_trials <- segmentation_acc_trial_exp1 / segmentation_acc_trial_exp2

if(save_output == T){
  ggsave(plot = plot_joint_segmentation_trials, 
         filename = here("03_output_graphics", "plot_joint_segmentation_trials.png"),
         width = 14, height = 14, units = "cm", dpi = 300)
}
```

# THE END
