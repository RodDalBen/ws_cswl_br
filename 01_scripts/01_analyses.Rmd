---
title: "Data analyses: Word segmentation and cross-situational word learning in parallel with Brazilians"
author: "Rodrigo Dal Ben"
date: "25/03/2021"
output: html_document
---

last update: 29/03/2021

# Brackground ######### FIX HERE ADD DETAILS

Data analyses for the study combining word segmentation (ws) and cross-situational word learning (cswl) in parallel. The study was performed with Brazilian adults (both in person and online). We also evaluate the effects of subtle phonotactic probabilities in this process.

**Reference:** Dal Ben R., Prequero I. T., Souza, D. H., & Hay, J. F. (in press). All together now: Word segmentation, cross-situational word learning and phonotactics in pareallel. *Journal ...*

**Doubts & suggestions:** <dalbenwork@gmail.com>

# Load packages
```{r load package}
library(tidyverse)
library(tidylog)
library(boot)
library(gmodels)
library(lme4)
library(brms)
library(sjPlot)
library(patchwork)
library(janitor)
library(RColorBrewer) 
library(here)

# avoid scientific notation
options(scipen = 0)

# color-blind palette
cb_pal <- c("#E69F00", "#009E73", "#0072B2", "#D55E00", "#999999", "#000000") 
```

# Prepare data

```{r load data}
# load full data
load(here("02_data/data_ws_cswl_br.rda"))

# change speech_version to factor
data_ws_cswl_br <- 
  data_ws_cswl_br %>% 
  mutate(speech_version = factor(speech_version, levels = c("L_balanced", "L_aligned", "L_conflict")))

levels(data_ws_cswl_br$speech_version)

# check number of participants on each experiment and speech version
data_ws_cswl_br %>% group_by(experiment, speech_version) %>% distinct(p_n_unique) %>% count()
```

## Remove inattentive/non-compliance

For the **go/no-go condition** (online data collection) we remove participants who: 

1. Had responses with reaction time greater than 3 SDs
2. Failed in at any of the 5 catch trials during training
3. Failed at any of the 6 catch trials at word segmentation test
4. Reported using cellphone (against instructions)
5. Reported annotating during the task (against instructions). 

```{r inattentive/non-compliance}
# reaction time of catch trials
rt_inatt_study2 <- 
  data_ws_cswl_br %>% 
  filter(experiment == "Study 2",
         trial_type %in% c("catch test ws", "catch training")
         ) %>% 
  group_by(trial_type) %>% 
  summarise(avg_rt = mean(rt, na.rm = T), 
            rt_3sd = 3*sd(rt, na.rm = T),
            cutoff_low = avg_rt - rt_3sd,
            cutoff_up = avg_rt + rt_3sd,
            )

# inattention by participant and trial type
inatt_study2 <- 
  data_ws_cswl_br %>% 
  filter(experiment == "Study 2",
         trial_type %in% c("catch cellphone", "catch annotation", "catch test ws", "catch training") # 5
         ) %>% 
  group_by(p_n_unique, trial_type) %>% 
  mutate(    
    is_correct = case_when(trial_type == "catch cellphone" & key_pressed == "n" ~ 1,
                           trial_type == "catch cellphone" & key_pressed == "s" ~ 0,
                           trial_type == "catch annotation" & key_pressed == "n" ~ 1,
                           trial_type == "catch annotation" & key_pressed == "s" ~ 0,
                           T ~ as.double(is_correct)),
    include_rt = case_when(trial_type == "catch test ws" & 
                             rt < rt_inatt_study2$cutoff_up[1] & rt > rt_inatt_study2$cutoff_low[1] ~ T,
                           trial_type == "catch training" & 
                             rt < rt_inatt_study2$cutoff_up[2] & rt > rt_inatt_study2$cutoff_low[2] ~ T,
                           T ~ F)
    ) %>%
  summarise(sum_is_correct = sum(is_correct, na.rm = T),
            sum_rt = sum(include_rt, na.rm = T)
            ) %>%
  mutate(include_is_correct = case_when(trial_type == "catch test ws" & sum_is_correct == 6 ~ T, 
                                        trial_type == "catch training" & sum_is_correct == 5 ~ T, 
                                        trial_type == "catch cellphone" & sum_is_correct == 1 ~ T, 
                                        trial_type == "catch annotation" & sum_is_correct == 1 ~ T,
                                        T ~ F),
         include_rt = case_when(trial_type == "catch test ws" & sum_rt != 6 ~ F, 
                                trial_type == "catch training" & sum_rt != 5 ~ F, 
                                T ~ T),
         include = if_else(include_is_correct == T & include_rt == T, T, F)
         )

# inattention by trial type
inatt_trial_type <- 
  inatt_study2 %>% 
  group_by(trial_type) %>% 
  summarise(include_is_correct = sum(include_is_correct),
            include_rt = sum(include_rt),
            include_final = sum(include))

# inattention by participant
inatt_participant <- 
  inatt_study2 %>% 
  group_by(p_n_unique) %>% 
  summarise(include_final = if_else(sum(include) == 4, T, F))
  
# final list of excluded participants
exclude_list <- 
  inatt_participant %>% 
  filter(include_final == F) # 16 participants excluded (29 remaining)
  
# exclude participants from dataset
data_filtered_v1 <- 
  data_ws_cswl_br %>% 
  filter(!p_n_unique %in% exclude_list$p_n_unique)

# double check n by experiment and speech version
data_filtered_v1 %>% group_by(experiment, speech_version) %>% distinct(p_n_unique) %>% count() # 33 on go/no-go
```

## Remove outliers

We remove test trials (both ws and cswl), for all conditions, with reaction time greater than 3 SDs. 

```{r rt outliers}
# calculate sd
rt_3sd <-
  data_filtered_v1 %>% 
  group_by(experiment, speech_version, trial_type) %>% 
  filter(trial_type == "test ws" | trial_type == "test cswl") %>% 
  summarise(rt_avg = mean(rt, na.rm = T),
            rt_3sd = 3*sd(rt, na.rm = T),
            cutoff_low = rt_avg - rt_3sd,
            cutoff_up = rt_avg + rt_3sd)

rt_3sd

# visualize 3 SDs, facet by experiment/speech_version
data_filtered_v1 %>% 
  filter(trial_type == "test ws" | trial_type == "test cswl") %>% 
  ggplot(aes(x = rt)) +
  geom_histogram() +
  facet_wrap(speech_version ~ trial_type)

# remove outliers
data_filtered_v2 <- 
  data_filtered_v1 %>% 
  mutate(include_trial = case_when(trial_type == "test ws" & speech_version == "L_balanced" & rt > rt_3sd$cutoff_up[2] ~ F,
                                   trial_type == "test cswl" & speech_version == "L_balanced" & rt > rt_3sd$cutoff_up[1] ~ F,
                                   
                                   trial_type == "test ws" & speech_version == "L_aligned" & rt > rt_3sd$cutoff_up[4] ~ F,
                                   trial_type == "test cswl" & speech_version == "L_aligned" & rt > rt_3sd$cutoff_up[3] ~ F,
                                   
                                   experiment == "Study 1" & trial_type == "test ws" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[6] ~ F,
                                   experiment == "Study 1" & trial_type == "test cswl" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[5] ~ F,
                                   
                                   experiment == "Study 2" & trial_type == "test ws" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[8] ~ F,
                                   experiment == "Study 2" & trial_type == "test cswl" & 
                                     speech_version == "L_conflict" & rt > rt_3sd$cutoff_up[7] ~ F,
                                   
                                   T ~ T
                                   )
         )

# summary of exclude trials by experiment/speech_version
data_filtered_v2 %>% 
  filter(trial_type == "test ws" | trial_type == "test cswl") %>% 
  group_by(experiment, speech_version, include_trial, trial_type) %>% 
  count() %>% 
  spread(include_trial, n) %>% 
  mutate(perc_excl = `FALSE`/`TRUE`)

# exclude trials
data_filtered_v2 <- 
  data_filtered_v2 %>% 
  filter(include_trial == T) %>% 
  select(-include_trial) # 70 trials (1% overall)
```

# Demographics

Sample size, gge (average, sd, range), and gender.

```{r demographics}
# demographics
data_filtered_v2 %>% 
  group_by(p_n_unique) %>% 
  slice_head() %>%
  ungroup() %>% 
  group_by(experiment, speech_version) %>% 
  mutate(tmp_gender = if_else(gender == "female", 1, 0)) %>%
  summarise(n = n(), 
            female = sum(tmp_gender), 
            age_avg = round(mean(age, na.rm = T), 2),
            age_sd = round(sd(age, na.rm = T), 2),
            age_max = max(age, na.rm = T),
            age_min = min(age, na.rm = T), 
            )
```

# Visualizations

* Mean performance on each task for each language;

* Correlation between performance on ws and cswl;

* Correlation between performance and self-evaluation (keys 1 to 4 transformed to proportion .25 to 1);

## Prepare data

Summary data, 1 data point per participant. 

```{r summary data plots}
# summary data for performance plot
data_summ_plot <- 
  data_filtered_v2 %>% 
  group_by(experiment, speech_version, p_n_unique, trial_type) %>%
  filter(trial_type %in% c("self evaluation cswl", "self evaluation ws", "test ws", "test cswl")) %>% 
  mutate(trial_type = factor(trial_type, levels = c("test ws", "test cswl", "self evaluation ws", "self evaluation cswl")),
         resp = case_when(trial_type == "self evaluation ws" | trial_type == "self evaluation cswl" ~ as.integer(key_pressed), 
                                    T ~ is_correct)) %>% 
  summarise(avg_resp = mean(resp, na.rm = T))

data_summ_plot

# summary data for correlation plot
# convert from 1, 2, 3, 4 to 0.25, 0.5, 0.75, 1 (respectively)
data_summ_correlation <- 
  data_summ_plot %>% 
  group_by(experiment, speech_version, p_n_unique) %>% 
  mutate(avg_resp = if_else(trial_type %in% c("self evaluation ws", "self evaluation cswl"), avg_resp*0.25, avg_resp)
         ) %>%
  spread(trial_type, avg_resp)

data_summ_correlation
```

## Plots

Performance plots

#**ADD**
- statistical annotation (https://indrajeetpatil.github.io/ggstatsplot/)
- WS: Study 2 by stimuli type
- CSWL = by pair frequency

```{r performance plot}
# Study 1: performance plot
data_summ_plot %>% 
  filter(experiment == "Study 1",
         trial_type %in% c("test ws", "test cswl")) %>% 
  ggplot(aes(x = speech_version, y = avg_resp, color = trial_type)) +
  geom_violin(position = position_dodge(0.8), alpha = 0.1, size = 0.3) +
  geom_point(position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), alpha = 0.3) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = 0.8)) + # boot CIs
  scale_color_manual(values = cb_pal, name = "Task", labels = c("Segmentation", "Mapping")) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  scale_x_discrete() +
  annotate("segment", x = 0.65, xend = 1, y = 0.5, yend = 0.5, linetype = "dashed") + # chance level ws
  annotate("segment", x = 1.65, xend = 2, y = 0.5, yend = 0.5, linetype = "dashed") + 
  annotate("segment", x = 2.65, xend = 3, y = 0.5, yend = 0.5, linetype = "dashed") + 
  annotate("segment", x = 1, xend = 1.35, y = 0.25, yend = 0.25, linetype = "dashed") + # chance level cswl
  annotate("segment", x = 2, xend = 2.35, y = 0.25, yend = 0.25, linetype = "dashed") +
  annotate("segment", x = 3, xend = 3.35, y = 0.25, yend = 0.25, linetype = "dashed") +
  labs(title = "Study 1", y = "Proportion of correct selection", x = "Speech version") + 
  theme_bw() +
  theme(legend.title.align = 0.5)

# Study 2: performance plot
data_summ_plot %>% 
  filter(experiment == "Study 2",
         trial_type %in% c("test ws", "test cswl")) %>% 
  ggplot(aes(x = speech_version, y = avg_resp, color = trial_type)) +
  geom_violin(position = position_dodge(0.8), alpha = 0.1, size = 0.3) +
  geom_point(position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), alpha = 0.3) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = 0.8)) + # boot CIs
  scale_color_manual(values = cb_pal, name = "Task", labels = c("Segmentation", "Mapping")) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  scale_x_discrete() +
  annotate("segment", x = 0.65, xend = 1, y = 0.5, yend = 0.5, linetype = "dashed") + # chance level ws
  annotate("segment", x = 1, xend = 1.35, y = 0.25, yend = 0.25, linetype = "dashed") + # chance level cswl
  labs(title = "Study 2", y = "Proportion of correct selection", x = "Speech version") + 
  theme_bw() +
  theme(legend.title.align = 0.5)

```

Study2: By stimuli type

```{r performance plots Study 2 stimuli type}
# Study 2: performance plot ws by stimuli type
data_filtered_v2 %>% 
  filter(experiment == "Study 2",
         trial_type == "test ws") %>% 
  ggplot(aes(x = speech_version, y = is_correct, color = distractor_audio_type_ws)) +
  #geom_violin(position = position_dodge(0.8), alpha = 0.1, size = 0.3) +
  geom_point(position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), alpha = 0.3) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = 0.8)) + # boot CIs
  #scale_color_manual(values = cb_pal, name = "Task", labels = c("Segmentation", "Mapping")) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  scale_x_discrete() +
  annotate("segment", x = 0, xend = 2, y = 0.5, yend = 0.5, linetype = "dashed") + # chance level ws
  #annotate("segment", x = 1, xend = 1.35, y = 0.25, yend = 0.25, linetype = "dashed") + # chance level cswl
  labs(title = "Study 2 - Word segmentation", y = "Proportion of correct selection", x = "Speech version") + 
  theme_bw() +
  theme(legend.title.align = 0.5)

# Study 1 & 2: performance plot
data_filtered_v2 %>% 
  filter(#experiment == "Study 2",
         trial_type == "test cswl") %>% 
  ggplot(aes(x = speech_version, y = is_correct, color = freq_pair)) +
  #geom_violin(position = position_dodge(0.8), alpha = 0.1, size = 0.3) +
  geom_point(position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), alpha = 0.3) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = 0.8)) + # boot CIs
  #scale_color_manual(values = cb_pal, name = "Task", labels = c("Segmentation", "Mapping")) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  scale_x_discrete() +
  #annotate("segment", x = 0.65, xend = 1, y = 0.5, yend = 0.5, linetype = "dashed") + # chance level ws
  annotate("segment", x = 0, xend = 4, y = 0.25, yend = 0.25, linetype = "dashed") + # chance level cswl
  labs(title = "Study 2 - CSWL", y = "Proportion of correct selection", x = "Speech version") + 
  facet_wrap(~ experiment) +
  theme_bw() +
  theme(legend.title.align = 0.5)

```

Correlation plots

**ADD**
- edit the legend for the `geom_count()`
- consider plotting by participant and reporting the stats for the `rmcorr` (repeated measures correlation)
- because the number of trials is different for cswl and ws, consider aggregating into 3 or 5 bins and comparing the bins per participant. They violate the assumption of independence, but is better than a single aggregate point per participant.

```{r correlation plots}
# segmentation and mapping
data_summ_correlation %>% 
  ggplot(aes(x = `test ws`, y = `test cswl`)) +#, color = speech_version)) +
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", color = "dark grey", alpha = 0.3) +
  facet_wrap(experiment ~ speech_version) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_size_area() +
  labs(x = "Proportion of corret segmentation", y = "Proportion of corret mapping") + 
  theme_bw()

# segmentation and self evaluation
a <- 
data_summ_correlation %>%
  ggplot(aes(x = `test ws`, y = `self evaluation ws`)) +#, color = speech_version)) +
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", color = "dark grey", alpha = 0.3) +
  facet_wrap(experiment ~ speech_version) +
  scale_size_area() +
  labs(title = "Segmentation performance and self-evaluation", 
       x = "Proportion of corret segmentation", 
       y = "Self-evaluation") + 
  theme_bw()

# mapping and self evaluation
b <- 
data_summ_correlation %>%  
  ggplot(aes(x = `test cswl`, y = `self evaluation cswl`)) +#, color = speech_version)) +
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", color = "dark grey", alpha = 0.3) +
  facet_wrap(experiment ~ speech_version) +
  scale_size_area() +
  labs(title = "Mapping performance and self-evaluation", 
       x = "Proportion of corret mapping", 
       y = "Self-evaluation") + 
  theme_bw()

## joint self-evaluations
a + b
```

# Statistics

## Descriptive

Mean correct & sd

```{r descriptive}
# descriptive - take it all with a grain of salt, the real stats is done with mixed models below
data_summ_plot %>% 
  group_by(experiment, speech_version, trial_type) %>%
  summarise(avg = mean(avg_resp, na.rm = T), 
            sd = sd(avg_resp, na.rm = T),
            ci_low = gmodels::ci(avg_resp)[2],
            ci_high = gmodels::ci(avg_resp)[3],
            d = (avg - 0.5)/sd
            ) %>% 
  mutate(ci_low = if_else(trial_type %in% c("test ws", "test cswl"), ci_low, NA_real_),
         ci_high = if_else(trial_type %in% c("test ws", "test cswl"), ci_high, NA_real_),
         d = if_else(trial_type %in% c("test ws", "test cswl"), d, NA_real_),
         
         avg = if_else(trial_type %in% c("self evaluation ws", "self evaluation cswl"), avg*0.25, avg),
         sd = if_else(trial_type %in% c("self evaluation ws", "self evaluation cswl"), sd*0.25, sd)
         ) 
```

## Inferential

#**ADD**:
- Analysis of `freq_pair` on cswl

We run 4 analyses:

1. Frequentist Logistic mixed model (`ws`, `cswl`);
2. Correlations:
  2.1. Between `ws` and `cswl` performance; 
  2.2. Between `self evaluation` and `ws` or `cswl` performance;
3. Bayesian Logistic mixed model (`ws`, `cswl`);


Given our binary outcome, odds ratio (OR) for each predictor serve as **effect sizes** estimations.

### Frequentist

- Study 1: Balanced (intercept) -> Aligned -> Conflict -> Conflict
- Study 2: Against chance;
- Maximal random effects structure: `(1|item) + (1|participant)`. The random slope & intercept `(participants|experiment)` does not have enough variability in the groups (3 words by 60 or 29 participants).

#### Word-segmentation

**Study 1**

```{r freq ws study 1}
# Study 1
mod_freq_ws_study1 <-
  data_filtered_v2 %>% 
  filter(experiment == "Study 1",
         trial_type == "test ws") %>% 
  glmer(is_correct ~ logit(chance_level) + speech_version + (1|target_audio_ws) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_ws_study1)
sjPlot::tab_model(mod_freq_ws_study1,
                  title = "Frequentist, Study 1 - Segmentation")
```

**Study 2**

On the go/no-go trials, participants heard either *non-words*, *words*, or *part-words*. Here we model the OR for each of this stimuli status.

```{r freq ws study 2}
# Study 2
mod_freq_ws_study2 <-
  data_filtered_v2 %>% 
  filter(experiment == "Study 2",
         trial_type == "test ws") %>% 
  glmer(is_correct ~ logit(chance_level) + distractor_audio_type_ws + (1|target_audio_ws) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_ws_study2)
sjPlot::tab_model(mod_freq_ws_study2,
                  title = "Frequentist, Study 2 - Segmentation")
```

#### Cross-situational word learning

**Study 1**

```{r freq cswl study 1}
# maximal random effects
mod_freq_cswl_study1 <-
  data_filtered_v2 %>% 
  filter(experiment == "Study 1",
         trial_type == "test cswl") %>% 
  glmer(is_correct ~ logit(chance_level) + speech_version*freq_pair + (1|target_visual) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_cswl_study1)
sjPlot::tab_model(mod_freq_cswl_study1,
                  title = "Frequentist, Study 1 - Mapping")
```

**Study 2**

#**CHECK** 
According to the plots and descriptive, this should be significantly above chance (but see the violin plot showing a fat distribution just on chance leve).

```{r freq cswl study 2}
# maximal random effects
mod_freq_cswl_study2 <-
  data_filtered_v2 %>% 
  filter(experiment == "Study 2",
         trial_type == "test cswl") %>% 
  glmer(is_correct ~ logit(chance_level) + freq_pair + (1|target_visual) + (1|p_n_unique),
        family = "binomial",
        data = .
        )

summary(mod_freq_cswl_study2)
sjPlot::tab_model(mod_freq_cswl_study2,
                  title = "Frequentist, Study 2 - Mapping")
```

### Correlation

**WS and CSWL performance correlation**

```{r correlation ws cswl performance}
data_summ_correlation %>% 
  group_by(experiment, speech_version) %>% 
  summarise(cor(`test ws`, `test cswl`, method = "spearman"))
```

**WS and CSWL self evaluation correlation**

```{r correlation ws cswl self evaluation}
data_summ_correlation %>% 
  group_by(experiment, speech_version) %>% 
  summarise(cor_ws = cor(`test ws`, `self evaluation ws`, method = "spearman"),
            cor_cswl = cor(`test cswl`, `self evaluation cswl`, method = "spearman"))
```


### Bayesian

#**CHECK** I will finish working on the frequentist model, and then come back here.

#### Word-segmentation

```{r bay ws study 1}
# maximal random effects
mod_bay_ws_study1 <-
  data_filtered_v2 %>% 
  filter(experiment == "Study 1",
         trial_type == "test ws") %>% 
  brm(is_correct ~ logit(chance_level) + speech_version + (1|target_audio_ws) + (1|p_n_unique),
      family = "bernoulli",
      data = .,
      iter = 10000,
      chains = 4
      )

summary(mod_bay_ws_study1)
sjPlot::tab_model(mod_bay_ws_study1,
                  title = "Bayesian, Study 1 - Segmentation")
```

#### Cross-situational word learning

```{r bay cswl Study 1}
# maximal random effects
mod_bay_cswl_study1 <-
  data_filtered_v2 %>% 
  filter(experiment == "Study 1",
         trial_type == "test cswl") %>% 
  brm(is_correct ~ logit(chance_level) + speech_version + (1|target_visual) + (1|p_n_unique),
      family = "bernoulli",
      data = .,
      iter = 10000
      )

summary(mod_bay_across_cswl)
sjPlot::tab_model(mod_bay_across_cswl)
```

Correlation - sample code (from exp3_seg)
```{r}
# corr between ws and cswl (correct, rt)
data_summary_corr_ws_cswl <- 
  data_summary %>% 
  select(id, trial_type, m_correct) %>% 
  group_by(id) %>% 
  spread(trial_type, m_correct)
```


### Frequentist
### Bayesian
# THE END
